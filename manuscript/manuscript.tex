% !TEX root = manuscript.tex
\documentclass[oneside]{zHenriquesLab-StyleBioRxiv}
\usepackage{url}
\usepackage{float}
\graphicspath{{./figs/}} % Path to figures:
\usepackage{soul}
\usepackage{color}
\leadauthor{Aquino}

\newcommand{\subf}[2]{%
   \normalfont\sffamily\fontsize{7}{9} \selectfont #2 \\
  {\small\begin{tabular}[t]{@{}c@{}}
  #1
  \end{tabular}}%
}

\begin{document}



\title{How wide scale deflections (WSDs) corrupt large scale network modelling of resting state fMRI.}
\shorttitle{Effect of large-scale coherent structures on modelling}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[1,*]{Kevin M. Aquino}
\author[1,2]{Gustavo Deco}
% \author[3]{Leonardo Gollo (ask)}
\author[1]{Alex Fornito}

\affil[1]{The Turner Institute for Brain and Mental Health, School of Psychological Sciences, and Monash Biomedical Imaging, Monash University, Victoria, Australia.}
\affil[2]{Universitat Pompeu Fabra, Barcelona, Spain.}
% \affil[3]{Queensland institute of Medical Research, Berghoffer, Brisbane, Australia.}


\maketitle

\begin{abstract}
Large-scale dynamics of the brain are routinely modelled using systems of dynamical equations that describe the evolution of population-level activity under certain biophysical constraints, and are coupled according to an empirically measured structural connection matrix. This modelling approach has been used to generate insights into the neural underpinnings of spontaneous brain dynamics, as recorded with techniques such as resting state functional MRI (fMRI).
However, parallel studies into the fMRI have revealed a wealth of structured noise – from small to large scale – and has revealed a lack of a consensus of which pre-processing and de-noising steps should be used. 
The specific choice of pre-processing models has a major impact on the final measures that compare population groups and understand underlying biology of human cortex, but these impacts are rarely considered in the modelling sphere. 
We show, using popular neural mass models, that key de-noising step leads to very different degrees of model fit and interpetations of findings.
These results question estimates of reported model parameters, model interpretation, and, in the worst case, model validity. 
We try to bridge the gap between theory and experiment by presenting recent quality control measures on the acquired data and the different types of structured noise. 
We hope to open the dialog between theory and experiment, which is necessary to advance large-scale brain network modelling. (having something less grand, statement is possibly too bold?)
\end{abstract}

\begin{keywords}
resting-state | fMRI | denoising | modelling | network | DiCER | GSR | rsfMRI
\end{keywords}

\begin{corrauthor}
kevin.aquino@monash.edu
\end{corrauthor}


\section*{Introduction}

% Plan for today - Thursday 9th Janurary 2020.
% Have a good rough crack at all of the Introduction (need to have it all filled out.)

% Plan for Wednesday - Have a rough crack of the methods

% Plan for Thursday - Have a crack including all of the holes in the results section

% Plan for Friday - Have a crack of the discussion (at least little bits)

% Plan for next week - Then have something to add to for the results and things 

Over the last three decades, functional magnetic resonance imaging (fMRI) has  focused on understanding the brain at ``rest'' or more specifically task-free. Imaging the brain in this state is sought to provide researchers an insight into the brain's idling dynamics - the default mode of the brain. Imaging the brain ``at rest'' is attractive paradigm as it can be easily acquired in the healthy population and has replaced many task-based analyses between groups where a balanced task response between patient groups and controls is difficult or in some cases impossible to develop (REFs).


Resting state fMRI has led to the discovery that the brain at rest exhibits synchronized fluctuations, revealing resting state networks \cite{fox2005human} that are robustly detected across individuals and species \cite{smith2009correspondence,beckmann2004probabilistic} (+Monkey and mice papers). These resting state networks are unique enough between individuals to allow subject identification \cite{finn2015functional,amico2018quest}, are related to independent behavioural measures \cite{li2019global} and the associated correlation structure is related to the underlying neural connectivity (Messe+Hagmann et al.). For these reasons resting state fMRI (rsfMRI) has potential promise in the clinical domain, as resting-state connectivity patterns are different between patient groups (REFs), change in response to treatment (REFs), and thus serve as potential biomarkers. 


There are many open questions as to the meaning of these networks, such as: what is driving these resting state fluctuations? (REFs) Does anatomical structure drive these co-ordinated flucations? (REFs) What drives differences between patient groups (Need refs for all of these). Large-scale biophysical models of cortical activity have sought to bridge the gaps in our understanding and have attempted to answer these questions. The majority of these models are at the mesoscopic population level, where the populations are on the scale of units derived from parcellations of cortex (REFs) and subcortex. The aim of these models is to simulate the resting brain and reproduce the functional connectivity network, where the nodes are the population units and the edges detail the empirical connectivity typically from correlations between nodes. Specifically, these are emboded in a functional connectivity (FC) matrix. These models have three critical ingredients - a biophysically realistic model of population dynamics, an anatomically defined connectivity structure, and a set of meaningful parameters. 


Firstly, at each node is a model that describes the net neural activity from each node. The translation from single neurons to a population are typically derived via neural mass (REFs) or neural field theory (REFs). Recent models have also been derived that capture the canonical dynamics that come both these theories - i.e. noisy oscillations described by a Hopf bifurcation (REFs Freyer, Robers, Gustavo). Although the form of these models can be quite complex, resting state can be viewed as a perturbation from a steady state and thus allow many models to be linearized, reducing the complexity allowing efficient compuation. In addition, at each node many populations can be ascribed within a single unit e.g. excitatory, inhibitory, and associated populations through the lamination of cortex though the coupling to all other nodes are mediated through excitatory populations. The resultant excitatory neural dynamics are then translated to a BOLD forward model that allows a direct simulation of resting state fMRI.


Secondly, coupling between nodes is imposed by anatomical connections that emulates how neurons are wired and exert influence to one another. This anatomical connectivity is usually defined from measurements that use diffusion weighted MRI and automated fibre tracking to and from each node (REF). These fibre tracks are undirected and summarized in a symmetric structual connectivity matrix that can detail the existence of connection between two nodes and/or the strength of this connection (REFs.). In some non-human modelling, asymmetric matrices can be imposed via invasive recordings that can track directionality of fibre tracks. Importantly, it is worth noting that these matrices are limited in their resolution in that inter-hemispheric connections are generally underestimated (REFs), have strong spatial dependence that roughly follows an exponential decay (REFs), and many modelling studies use an average structual connectivity matrix aggregated from many subjects. 


Lastly, each biophysical model requires two types of parameters - at the global and at the individual node level. The global parameter/s are used to scale the anatomical connections uniformly as the structual connectivity matrix is calculated without units compatible with the models. In almost all models, this global parameter is a hyper parameter that has a large influence on the dynamics - scaling all connections too high can result in largely synchronized activity and too low causes asynchronus fluctuations. This is typically tuned to maximise model fits while being in a comparable dynamic range. At the node level, the neural mass or neural field models use techniques that translate measured parameters from the neuronal scale to the mesoscopic scale. The first generation of these large-scale models use the same local parameters for each node (REFs), however with the advent of additional measurements - such as intracortical myelin markers (REFs) - recent models employ heterogenous population parameters that have improved model fitting. (see below).


Through the application to rsfMRI, large-scale biophysical modelling has found that structure largely guides functional connectivity in both humans (REF) and primates (REF). The accuracy of such modelling is usually determined by how well it can reproduce the functional connectivity matrix, and models have increased their accuracy as models have become more sophisticated and imaging has improved. Recently, there has been a shift to use additional metrics on simulated and empirical data to further investiage model accuracy and validity by using dynamic measures such as using time varying functional connectivity, metastability, and phase coherence (REFs add more?). In concert, additonal parameters are being allowed to vary to fit to these dynamic measures which has provided estimates of directed structual connectivity by allowing the structural connectivity to vary (DCM REFs, Gilson Refs) and estimates of brain wide variation of neural populations by allowing local node parameters to vary (REFs). These recent developments allow estimates of parameters that indirectly measure neuromodulatory process, which provide futher generative insights, understand the implications of neural deficits, and these parameters have potential to be biomarkers that are directly related to neural processes. 


% (will have to do something on fitting really.)


% What have they shown? Firstly, they can fit correlations really well, 
% Secondly, that structure really shapes rsfMRI connectivity to a large degree and that underlying ``hidden parameters'' such as neuromodulation etc can be inferred and possibly used to correlate to certain things. 

% and simulate dynamics present in large scale resting state fMRI (REFs). There have been numerous coritcal models, each providing accurate predictions of the network correlational stucture. Together, these models show the following (A,B,C,D ++ need to find the key findings and what people are saying).

The ease of recording rsfMRI, and the suitability to many biophysical models has seen the acceleration of studies acquiring and investigaing the brain at rest. However, with this advance, recent studies have relaved a wealth of confounding artefacts within rsfMRI such the presence of wide scale deflections (WSDs) correlated to head motion (REF), heart rate variability (REF), respiration (REF), time of acqusition (REF). Although there have been efforts over the last 30 years to remove these effects through physiological modelling (RETROICOR REF), improved motion correction algorithms (REF), fMRI acquisiton advancements (ME ref), and advancements in de-noising (MANY REFS) there is a large influence of motion and physiological confounds on rsfMRI. This is most clearly manifested in popularized ``carpet (or gray) plots'' which show temporal relationships of these confounds with rsfMRI (Power, Glasser, Aquino). In practise, this results in high global correlations functional correlations where the strength of these correlations have been shown to relate to motion (REF) or physiology (REF) making neural inferences from rsfMRI difficult to seperate from these processes. This issue is important in groups that naturally have differences in head motion (REFS) or physiology (REFS) which make neuronal differences are harder to determine. Through these confounds, there does not appear to be a clear concensus on the appropriate steps for not just de-noising but the order and type of steps with preprocessing pipelines - however there is a growing movement to standarize many of these steps (fMRIprep reference) and to utilzing large unified sources of data.


Ongoing efforts within the rsfMRI community has placed greater standards that analyze not just group-level metrics but capture artefacts at the individual level by analyzing spatiotemporal time series via carpet plots (REFS) and quality control (QC) metrics that measure the influence of motion or respiration on FC edges. These tools are being employed to critically evaulate existing and new tools that denoise fMRI data and are often used to question any denoising method \cite{ciric2017benchmarking,Parkes:2018dz} 


However, the modelling community has largely ignored these significant challenges within experimental rsfMRI. Equivalent comprehensive investigations on the effects of preprocessing, de-noising techniques, the visualisation of carpet plots or QC metrics have not penetrated the investigation of model outputs or inferences. Although the use of one particular de-noising strategy - global signal regression (GSR) - has been discussed (Messe and othe rpapers), its use or non-use is not standard and largely model dependent. Therefore, there is a gap in the field to determine whether WSDs influence model prediction, whether motion or respiration influences model estimates, and if WSDs influence model validity. 


Here, we investigate the effects of WSDs on modelling by employing recent techniques in the rsfMRI literature to a set of XX exisitng large-scale biophysical models. We find that the existence of WSDs influence model fits to a significant degree, and find that in some models increasing the accuracy/level of de-noising methods reduces model fits across many models. We find that many models are biased to modelling large scale coherent activity that is impossible (with many current methods) to disambiguate from potential sources of physiological or motion-driven noise. Second order neuronal fluctuations i.e. those that are not global do not fit very well on most models thus, we find that models need to be improved on the whole. We demonstrate this issue of bias to WSDs by showing that we can reduce down a recent model to a linear operation of degree and noise that outperforms models in terms of static FC and dynamic FC. We do find however, that heterogenoity can improve model accuracy and model second order effects that are less prone to WSDs driven by motion or physiology at the cost of model complexity. All analysis here is provided in open source toolboxes at XXX.


\section*{Methods}
% Here, we describe the methods in two distinct sections - resting state fMRI, which includes acqu
% The methods here are split up into X different parts. 

% Firstly, we talk about experiments then dynamical models.
 % Methods here describe the expermiental data and the mentioned dynamical models. 
\subsection*{Resting state fMRI}
\paragraph{}
Here, we used transparent, open rsfMRI datasets processed using open-source pipelines from \verb|fmriprep| \cite{esteban2019fmriprep} and the Human Connectome Project (HCP) (REF). 
\subsubsection*{Imaging data \& preprocessing}
We utilzed three open source data sets from the healthy controls of the UCLA Consortium for Neuropsychiatric Phenomics LA5c Study \cite{poldrack2016phenome} (v00016 \url{openneuro.org/datasets/ds000030/}), the Beijing-Zang dataset (\url{fcon_1000.projects.nitrc.org/fcpClassic/FcpTable.html}) and resting state fMRI from the HCP. The scanning parameters for these three datasets are described in \cite{esteban2019fmriprep}, \url{http://fcon_1000.projects. nitrc.org/fcpClassic/FcpTable.html} and Glasser et al. (be sure on the paper), respectively; a brief summary is in Table~\ref{tab:scanning_params}.

\begin{table*}[ht!]
\begin{center}
    \begin{tabular}{  p{2.5cm}  p{5cm}  l  p{1.5cm}  p{4cm} }
    % \hline
    \textbf{\sffamily Dataset} & \textbf{\sffamily BOLD parameters} & \textbf{\sffamily Volumes} & \textbf{\sffamily Subjects} & \textbf{\sffamily Notes} \\
    \hline
    UCLA LA5c Study \cite{poldrack2016phenome} & TE $=30$\,ms, 3\,mm Inplane resolution, 34 slices with 4\,mm slice thickness, FA$=90$, FOV$=192$\,mm, matrix = $64 \times 64$,
    Oblique and interleaved Gradient echo EPI sequences, TR $= 2$\,s & 152 & 121 & We focused on the healthy controls (from the original sample of 270 people), that included subjects aged 21--50.\\
    \hline
    Beijing-Zang \url{http://fcon_1000.projects.nitrc.org/} & TE$=30$\,ms, 3.125\,mm, Inplane resolution, 33 slices with 3.6\,mm, slice thickness, FA$=90$, FOV$=200$\,mm, matrix $=64 \times 64$ & 225 & 192 & Subjects were healthy controls. \\
    \hline
	HCP & TE$=30$\,ms, 3.125\,mm, Inplane resolution, 33 slices with 3.6\,mm, slice thickness, FA$=90$, FOV$=200$\,mm, matrix $=64 \times 64$ & 225 & 100 & Subjects were healthy controls. \\
    \hline
    \end{tabular}
    \caption{Summary of acquisition parameters for the functional MRI and structural MRI used in this study.
	Note: not all essential parameters were reported in the open repositories, we list those that were reported.
    \label{tab:scanning_params}}
\end{center}
\end{table*}

``Minimal'' preprocessing pipelines were used on the three datasets, where the UCLA and BZ utilized \verb|fmriprep| v1.1.1 as described in \cite{aquino2019identifying}. Briefly, this involves processing the T1-weighted anatomical images that involve: bias field correction, brain extraction, freesurfer segementation, and volume normalization to a standard MNI 152 Nonlinear Asymmetric templta version 2009c \cite{mni}. On the functional MRI, the minimal preprocessing steps involve slice time correction, motion correction, distortion correction using a template based $B_0$ image, and co-registration to the T1 anatomical image. The versions of code, specific details of the algorithms are detailed in the code described above. Functional imaging data from the HCP data were minimally preprocessed in a similar fashion, using the minimal HCP pipelines described in Glasser et al. (Find ref) however, an additional step was imposed to project the data into ``grayordinates'' which compactly represent data from grey matter cortex and subcortex. These grayordinates are described on a normalied template that has been surface registered for cortex data using the Multi. Sulcal matching algorithm, and volume-registered using fNIRT (REF) to MNI 152 space for subcortex data (REF). The purpose of having two different pipelines as we chose to use established data that have already undergone quality control so that these QC measures can be analyzed in the context of modelling. In addition, the comparisons due to de-noising levels are only to be interpreted within dataset as site effects between scanning is a major confound to functional connectivity measures. 

For transparency, the code to re-run all of these analyses are located at \vbox{\url{https://github.com/BMHLab/DiCER.git}}, and in the following sections we describe de-noising strategies that follow minimal preprocessing and standard outputs of fMRIprep. In our de-noising strategies we utilize two streams for the two datasets. 

\subsubsection*{De-noising strategies for UCLA and BZ} 

Firstly, for UCLA and BZ, Functional MRI data are analyzed within the MNI 152 Asymmetric 2009c space, which has been resampled to the native BOLD imaging dimensions, and we resampled any remaining anatomical masks/images to this space (including those that were not automatically resampled in the \verb|fmriprep| workflow). 

We restrict our analysis and visualizations to gray-matter voxels (GM), in UCLA and BZ, to minimize partial-volume effects, our analysis was restricted to voxels contained within the GM probability masks (calculated in fmriprep) thresholded at > 50\% probability.
We also excluded voxels with signal intensities that were below 70\% of the mean fMRI signal intensity to avoid contamination by voxels with low signal plagued by susceptibility and partial-volume effects.

ICA-based Automatic Removal Of Motion Artifacts (AROMA) was used to generate noise regressors for use in the non-aggressive variant of the method \cite{aroma}. Regressors were calculated on the spatially smoothed variant of the minimally preprocessed images (as described within \verb|fmriprep| as a $6$ mm FHWM kernel) and then applied to the unsmoothed preprocessed images,

Following ICA-AROMA, we extracted mean time courses from eroded masks (using a 3x3x3 erosion kernel) of the WM and CSF. The masks were generated by following \citet{Parkes:2018dz} and \citet{power2017sources}, where CSF and WM ROIs were created from tissue probability maps in \verb|fmriprep|. We eroded the WM mask five times and the CSF mask once. Erosion is crucial to avoid partial-volume effects from gray matter, which inflates the correlation between WM/CSF estimates and the global-mean signal \cite{power_fd_dvars,Parkes:2018dz}.
We extracted these signals from the AROMA-denoised data, as performed in \citet{aroma}.

The above steps are fairly standard and accepted de-noising techniques, however wide scale deflections (WSDs) are present following these pipelines which correlation structure is related to motion, corrupting neuronal inferences. Thus, further de-noising methods are described using the controversial Global signal regression (GSR), and Diffuse Cluster Estimation and Regression (DiCER) which has been shown to mitigate these effects in a different way. 

For GSR, estimates of the mean gray-matter signal is a proxy for the global signal as it is highly correlated to the mean signal from the entire brain and contributes the most to the signal \cite{power2017sources,Glasser:2018dt}. We thus refer to regression of this signal from fMRI gray-matter regression (GMR) for clarity. 

As shown in \cite{aquino2019identifying}, fMRI following ICA-AROMA and GMR are left with a wide variety of WSDs that are correlated to motion or physiology, that are particualry revealed under a re-ordering of the conventional carpet plots. DiCER is a method that targets these WSDs by focusing on diffuse, weakly correlated clusters, and has revealed to improve statistical sensitivity within datasets. We utilze DiCER settings as described within \citet{aquino2019identifying} to retrive noise regressors.

Using the noise-signal estimates, we perform three noise corrections, with
(i) regression with the WM and CSF physiological signals, denoted as `+2P'; and
(ii) regression with WM, CSF and GM signals, denoted as `+2P+GMR'.
(iii) regression with WM, CSF and DiCER regressors, denoted as `+2P+DiCER'.
The first two models were applied after ICA-AROMA denoising in a single step using ordinary least squares regression implemented in \verb|fsl_regfilt|, and the last model was applied post (i) as DiCER is targetting residual noise. 

The data, including the minimally preprocessed data, were then detrended with a 2nd order polynomial and high-pass filtered at 0.005\,Hz using AFNI's \verb|3dTproject|. This procedure resulted in four datasets for each subject, labeled `MPP',`ICA-AROMA+2P', `ICA-AROMA+2P+GMR', `ICA-AROMA+2P+DiCER'. 
% Finally, we note that for all results from Sections I to III, none of the fMRI time series were spatially smoothed for visualization, denoising, nor statistical analyses.”

\subsubsection*{De-noising strategies for HCP} 

Talk about denoising on HCP

MPP
MPP+sICA+FIX
MPP+sICA+FIX+GMR
MPP+sICA+FIX+DiCER

Talk about the strucual connectivity matrix.

Again, we stress that the results comparing differences in model fits can only be compared within each dataset as to remove well-known confounds of site, scanner quality and populations.

\subsubsection*{Quality control methods} 

\subsection*{Dynamical models}

Also talk about using the BCT. 

Homogenous models:
Balanced EI
Hopf
BTF

Heterogenous Node:
Hopf

Hetergenous Edge:
Hopf+ANEC

\section*{Results I: How WSDs influence model fits}

Show the results + show carpet plots and stuff

\section*{Results II: The noisy degree model}

Show how it comes about. 

\section*{Results III: ANEC}

\section*{Discussion}

\section*{Acknowledgements}


\begin{acknowledgements}
AF was supported by the Australian Research Council (ID: FT130100589), National Health and Medical Research Council (NHMRC; ID: 1104580), and the Sylvia and Charles Viertel Charitable Foundation. The authors thank Stuart Heitmann for support of the Brain connectivity toolbox, and Christopher honey and Olaf sporns for sharing code. 
\end{acknowledgements}

\section*{Bibliography}
\bibliographystyle{benbibstyle}
\interlinepenalty=10000
\bibliography{GSR_references}

%% You can use these special %TC: tags to ignore certain parts of the text.
%TC:ignore
%the command above ignores this section for word count
\onecolumn
\newpage


%  this study is going to bridge that gap by using biophyiscal models of the certain kind. Will show the effects that WSDs provide, showing how WSDs can influence findings and corrupt the work. Here, we bring into question the role and urge QC-FC type of measures as well as carpet plots. We end with a note on how things can be improved with heteroengous models but at the cost of model complexity. 


% What i think is instead cool is to have two different sections, 

% firstly show the effects that different preprocessing has and relationships to data. 
% We find a very important influence of global fluctuations and state that without careful consideration we are only really fitting this large oscillations. We can just use the ND model instead.

% Then say from a modelling point of view this is very attractive as if there is a complex network resting state fMRI can be seen as small pertubations, and from a dynamic perspective this allows a large amount of dynamics that are applicable from other sources.



% Things to talk about in the introduction:
% + General large-scale network modelling
% + What is being fitted (rsfMRI correlations)
% + Problems in the field regarding Large-coherent structures
% + Largely ignore by the modelling community (no real discussion of this)
% 	-- Discussion more on GSR vs noGSR (Hannes paper, Messe et al as well)
% + If we treat model simulations as numerical experiments we can then understand the simulated data in the same light
% + Summary of the rest of the paper - starting with a special case of the balanced EI model, using the tools and the models under different preprocessing lights. Introduce the noisy-degree model (could be something that is really interesting on its own, but it does not need anything else.)


% Over the last two decades, functional magnetic resonance imaging (fMRI) has heavily focused on understanding the brain "at rest". 
% Imaging the brain at ``rest'' ,or more accurately task-free,   is thought to accentuate the brain's complex functional networks (REFS) under the premise that key networks of brain function have a correlated structure (REFS). 
% This paradigm has lead to the discovery of robust resting networks that are altered once the brain is engaged tasks, are altered in disease, and consistent across populations as well as species. 
% These discoveries have lead to various questions -- such as what is the role of these networks? what are the key elements are altered during disease, and importantly how stucture shapes cortical function.



% Talk about the tools to de-noise: popular methods are typically seen in the following light - take estimates 


% This crisis in the experimental and data analysis litertaure has largely been ignored in large scale biopyhysical modelling. In This crisis


% Hence, this has been a large focus of large scale brain dynamics. 

% Hence, there has been a large focus to understand the data acquired from this paradigm 

%  although easy to acquire, has presented a number of challenges there has been a paradigm shift to stray away from understanding task specific brain activity to 


% Functional magnetic resonance imaging (fMRI) of the brain at rest has brought upon a plehtora of studies to understand the correlational structure of cortex. A number of studies have used this resting paradigm 


% Need to mention that very bad prepro has been used. 

% \section*{Methods 1: Experimental data}

% \section*{Methods 2: Brain network modelling}
% generic theory:
% \begin{equation}
% 	\frac{d}{dt}z_{i}(t) = f(A,{\bf z}) + I.
% \end{equation}
% where $A$ is the structural connectivity matix 

% \section*{The premise: Resting state functional networks}

% Here talk about the results and what is extracted. Then talk about the modelling from structure to function, essentially what people have been doing. State that there has been success. 

% Then state the problems, and they have unfortunately been treated seemingly independently.

% Independent problems:
% From the modeling side: Homogenous vs heterogenous. Types of different dynamical mechanisms. Types of oscillatory models.
% From the data side: preprocessing, global signal regression? inter subject registration

% Fusion problems:
% Where worlds meet:
% Fitting models to data
% - Find fitting statistics FCD, FC, Correlations
% - Making inferences from data
% - GSR the assumption that it is the panacea. From a modeling perspective we are removing the global neural mode however this is NOT equivalent to what is happening, the reason is different. 

% Assumptions, that all problems listed above have been handled/sorted/agreed upon in the field. The question is how much does it matter? Here we will strive to show the problems associated with it -- FC and FCD are not enough as many models can fit the data. Show in a case study in a very simplified model. We show how much Global signal changes the fitting -- GSR is not adequate however. 

% Show that we are not ready yet to make robust inferences, we need better models and cleaner data.

% \section*{Theory and results}

% Add in stuff to do with 

% The problems with FC and FCD

% Definitions of data \\
% Definitions of global signals \\
% Definitions of models (heterogenous vs homogenous models) \\
% Show different candidates of metrics: FC,FCD and correlations.
% Show the different types \\

% \section*{Theory and predictions}

% How many sample points are needed?
% Perhaps something we should also ask is how much of the time domain needed for the functional connectivity emerge as a robust measure -- timings etc. Which edges take the longest.

% Perhaps we need a certainty. 

% \section*{Results from modeling:}
% Need to have a table here

% \section*{ways to improve things}
% We take correlations blindly in functional networks on large scale connectivity. Perhaps however we need estimates of uncertainty on each node -- this way the model does not have to prove the existence of this connection. 

% How robust are connections to preprocessing methods and timing windows? Then fitting needs to work on this assumption.

% Heterogeneity is the answer. but preprocessing matters. 

% GSR is probably not the answer.

% ANEC

% \section*{Points that need to be discussed/mentioned here}

% There is a big divide between modeling and experimental expertise \\
% There is an assumption of quality on each side \\
% Preprocessing affects the model findings and interpretation \\
% Discussion of homogenous vs heterogenous models\\
% The balanced EI model shows although good fit without GSR, it unfortunately not so good. \\
% The interplay between theory and experiment. \\
% Does it matter? we have a test scenario SCZ vs CTL -- what are the differences? \\
% Models fit best with the worst kind of preprocessing.

% \section*{Discussion}

% What is actually being modelled? Is this brain function, or just a perturbation of a resting idled brain? This is not generalizable really. If one were to take a simple visual response what do we see? Should the models capture all this behaviour?

% We need better measures - FCD? not sure if this is enough, we need more stuff. Also need to have predictive validity. 


% also idea, shift the last few Gs stuff to negative see what GSR does to it.

\end{document}
